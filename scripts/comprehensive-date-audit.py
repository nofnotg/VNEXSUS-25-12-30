#!/usr/bin/env python3
"""
í¬ê´„ì  ë‚ ì§œ ê°ì‚¬ - Baseline vs OCR ë¹„êµ
"""
import json
import re
from pathlib import Path
from typing import Set

def extract_dates_comprehensive(text: str) -> Set[str]:
    """ëª¨ë“  ë‚ ì§œ íŒ¨í„´ ì¶”ì¶œ (ì •ê·œí™” ì „)"""
    patterns = [
        (r'(\d{4})[-](\d{1,2})[-](\d{1,2})', '-'),
        (r'(\d{4})[.](\d{1,2})[.](\d{1,2})', '.'),
        (r'(\d{4})[/](\d{1,2})[/](\d{1,2})', '/'),
        (r'(\d{4})\s*ë…„\s*(\d{1,2})\s*ì›”\s*(\d{1,2})\s*ì¼', 'ë…„'),
    ]

    dates = {}  # key: normalized, value: original
    for pattern, sep in patterns:
        for match in re.finditer(pattern, text):
            year, month, day = match.groups()
            normalized = f"{year}-{month.zfill(2)}-{day.zfill(2)}"
            original = match.group(0)
            if normalized not in dates:
                dates[normalized] = original

    return dates

# Case10 ë¶„ì„
print("=" * 100)
print("Case10 ë‚ ì§œ ê°ì‚¬")
print("=" * 100)

baseline_file = Path("/home/user/VNEXSUS-25-12-30/src/rag/case_sample/Case10_report.txt")
ocr_file = Path("/home/user/VNEXSUS_reports_pdf/offline_ocr_samples/offline_ocr_samples/2025-12-26T06-20-25-463Z/Case10/Case10_offline_ocr.json")

# Baseline ë‚ ì§œ
baseline_text = baseline_file.read_text(encoding='utf-8')
baseline_dates = extract_dates_comprehensive(baseline_text)

print(f"\nğŸ“‹ Baseline ë‚ ì§œ: {len(baseline_dates)}ê°œ")
for normalized, original in sorted(baseline_dates.items())[:15]:
    print(f"  {normalized} (ì›ë³¸: {original})")

# OCR ë‚ ì§œ
with open(ocr_file, encoding='utf-8') as f:
    data = json.load(f)

ocr_text = '\n'.join([block.get('text', '') for block in data['blocks']])
ocr_dates = extract_dates_comprehensive(ocr_text)

print(f"\nğŸ“¦ OCR ë‚ ì§œ: {len(ocr_dates)}ê°œ")
for normalized, original in sorted(ocr_dates.items())[:15]:
    print(f"  {normalized} (ì›ë³¸: {original})")

# ë¹„êµ
baseline_only = set(baseline_dates.keys()) - set(ocr_dates.keys())
ocr_only = set(ocr_dates.keys()) - set(baseline_dates.keys())
common = set(baseline_dates.keys()) & set(ocr_dates.keys())

print(f"\nğŸ” ë¹„êµ ê²°ê³¼:")
print(f"  ê³µí†µ: {len(common)}ê°œ")
print(f"  Baselineì—ë§Œ ìˆìŒ (OCR ëˆ„ë½): {len(baseline_only)}ê°œ")
print(f"  OCRì—ë§Œ ìˆìŒ (ì¶”ê°€ ê²€ì¶œ): {len(ocr_only)}ê°œ")

if baseline_only:
    print(f"\nâŒ OCRì´ ëˆ„ë½í•œ ë‚ ì§œ ({len(baseline_only)}ê°œ):")
    for date in sorted(baseline_only):
        original = baseline_dates[date]
        print(f"  {date} (baseline ì›ë³¸: {original})")

        # Baselineì—ì„œ í•´ë‹¹ ë‚ ì§œê°€ ìˆëŠ” ë¼ì¸ ì°¾ê¸°
        for i, line in enumerate(baseline_text.split('\n'), 1):
            if original in line:
                print(f"    â†’ Baseline Line {i}: {line.strip()[:120]}")
                break

print("\n" + "=" * 100)
print("í•µì‹¬ ë°œê²¬ì‚¬í•­")
print("=" * 100)
print()
print("1. OCRì´ Baselineì— ìˆëŠ” ì¼ë¶€ ë‚ ì§œë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í•¨")
print("2. ì´ëŠ” OCR ì •í™•ë„ ë¬¸ì œì´ê±°ë‚˜ ë¬¸ì„œ ì´ë¯¸ì§€ í’ˆì§ˆ ë¬¸ì œì¼ ìˆ˜ ìˆìŒ")
print("3. Baseline ë³´ê³ ì„œëŠ” ì‚¬ëŒì´ ì‘ì„±í•œ ê²ƒìœ¼ë¡œ, ì‹¤ì œ ë¬¸ì„œ ë‚´ìš©ì„ ë°˜ì˜")
print("4. ë”°ë¼ì„œ 'ì˜¤ë¥˜'ë¡œ ë¶„ë¥˜ëœ ë‚ ì§œë“¤ì€ ì‹¤ì œë¡œëŠ” OCRì˜ ëˆ„ë½(False Negative)")
print()
print("ê°œì„  ë°©í–¥:")
print("  - OCR í›„ì²˜ë¦¬: ë¬¸ë§¥ ê¸°ë°˜ ë‚ ì§œ ë³µì›")
print("  - LLM í™œìš©: ì˜ë£Œ ë³´ê³ ì„œ ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ ë‚ ì§œ ì¶”ë¡ ")
print("  - í•˜ì´ë¸Œë¦¬ë“œ: OCR + LLM ë‚ ì§œ ì¶”ì¶œ ì¡°í•©")
