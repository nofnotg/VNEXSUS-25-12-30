#!/usr/bin/env python3
"""
GPT vs Claude ëª¨ë¸ ë¹„êµ ê²€ì¦ (Gemini SSL ì´ìŠˆë¡œ ì œì™¸)
- GPT-4o-mini (OpenAI)
- Claude 3.5 Haiku (Anthropic)
"""
import json
import re
import os
import asyncio
import ssl
import httpx
from pathlib import Path
from typing import Set, Dict, List
from datetime import datetime

# SSL verification bypass for WSL environment (testing only)

# API í´ë¼ì´ì–¸íŠ¸
try:
    from openai import AsyncOpenAI
    HAS_OPENAI = True
except ImportError:
    HAS_OPENAI = False
    print("âš ï¸  OpenAI íŒ¨í‚¤ì§€ ì—†ìŒ")

try:
    from anthropic import AsyncAnthropic
    HAS_ANTHROPIC = True
except ImportError:
    HAS_ANTHROPIC = False
    print("âš ï¸  Anthropic íŒ¨í‚¤ì§€ ì—†ìŒ")

def extract_dates_from_text(text: str) -> Set[str]:
    """í…ìŠ¤íŠ¸ì—ì„œ ë‚ ì§œ ì¶”ì¶œ (ì •ê·œì‹)"""
    patterns = [
        r'(\d{4})[-](\d{1,2})[-](\d{1,2})',
        r'(\d{4})[.](\d{1,2})[.](\d{1,2})',
        r'(\d{4})[/](\d{1,2})[/](\d{1,2})',
        r'(\d{4})\s*ë…„\s*(\d{1,2})\s*ì›”\s*(\d{1,2})\s*ì¼',
    ]

    dates = set()
    for pattern in patterns:
        for match in re.finditer(pattern, text):
            year, month, day = match.groups()
            normalized = f"{year}-{month.zfill(2)}-{day.zfill(2)}"
            if is_valid_date(normalized):
                dates.add(normalized)

    return dates

def is_valid_date(date_str: str) -> bool:
    """ë‚ ì§œ ìœ íš¨ì„± ê²€ì¦"""
    try:
        year, month, day = map(int, date_str.split('-'))
        if year < 1950 or year > 2100:
            return False
        if month < 1 or month > 12:
            return False
        if day < 1 or day > 31:
            return False

        days_in_month = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]
        is_leap = (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0)

        if month == 2 and is_leap:
            return day <= 29

        return day <= days_in_month[month - 1]
    except:
        return False

def merge_ocr_blocks(blocks: List[Dict]) -> str:
    """OCR ë¸”ë¡ ë³‘í•©"""
    sorted_blocks = sorted(blocks, key=lambda b: (b.get('bbox', {}).get('page', 0), b.get('bbox', {}).get('y', 0)))

    merged_text = ''
    last_page = -1

    for block in sorted_blocks:
        page = block.get('bbox', {}).get('page', 0)
        text = block.get('text', '')

        if page != last_page and last_page != -1:
            merged_text += '\n\n=== í˜ì´ì§€ êµ¬ë¶„ ===\n\n'
        last_page = page

        merged_text += text + ' '

    return merged_text.strip()

def create_date_extraction_prompt(merged_text: str, existing_dates: List[str]) -> str:
    """ë‚ ì§œ ì¶”ì¶œ í”„ë¡¬í”„íŠ¸ ìƒì„± (ìµœì í™” ë²„ì „)"""
    existing_info = f"\n\nì´ë¯¸ ì¶”ì¶œëœ ë‚ ì§œ: {', '.join(existing_dates)}\nìœ„ ë‚ ì§œë“¤ë„ í¬í•¨í•˜ë˜, ì¶”ê°€ë¡œ ëˆ„ë½ëœ ë‚ ì§œê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”." if existing_dates else ""

    return f"""ë‹¤ìŒì€ ì˜ë£Œë³´í—˜ ì†í•´ì‚¬ì • ë³´ê³ ì„œì˜ OCR ì¶”ì¶œ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.

âš ï¸ ì¤‘ìš”: ì•„ë˜ í…ìŠ¤íŠ¸ëŠ” í‘œì—ì„œ ì¶”ì¶œë˜ì–´ ê¸€ì ê°„ ê³µë°±ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì˜ˆì‹œ:
- "ë³´ í—˜ ê¸° ê°„" = "ë³´í—˜ê¸°ê°„"
- "ê³„ ì•½ ì¼" = "ê³„ì•½ì¼"
- "ì‚¬ ê³  ë°œ ìƒ ì¼" = "ì‚¬ê³ ë°œìƒì¼"
- "ì… ì› ì¼" = "ì…ì›ì¼"

ì´ëŸ° íŒ¨í„´ì˜ í…ìŠ¤íŠ¸ì—ì„œë„ ë‚ ì§œë¥¼ ë¹ ì§ì—†ì´ ì¶”ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.

ğŸ“… ë°˜ë“œì‹œ ì¶”ì¶œí•´ì•¼ í•  ë‚ ì§œ (ìš°ì„ ìˆœìœ„ìˆœ):
1. **ë³´í—˜ ê³„ì•½ì¼/ê°€ì…ì¼** (ê³„ì•½ì„œ ìƒë‹¨, í‘œ ì•ˆ)
2. **ë³´í—˜ ê¸°ê°„** (ì‹œì‘ì¼, ì¢…ë£Œì¼) - í‘œ ì•ˆì—ì„œ "ë³´ í—˜ ê¸° ê°„", "ê³„ì•½ê¸°ê°„" ë“±ìœ¼ë¡œ í‘œì‹œ
3. **ì‚¬ê³  ë°œìƒì¼** - "ì‚¬ ê³  ì¼", "ë°œìƒì¼ì" ë“±
4. **ë³‘ì› ë‚´ì›ì¼/ì…ì›ì¼/í‡´ì›ì¼** - "ë‚´ ì› ì¼", "ì… ì›", "í‡´ ì›"
5. **ì§„ë‹¨ì¼/ê²€ì‚¬ì¼/ìˆ˜ìˆ ì¼** - "ì§„ë‹¨ì¼ì", "ê²€ ì‚¬ ì¼", "ìˆ˜ ìˆ  ì¼"
6. **ì²­êµ¬ì¼/ì ‘ìˆ˜ì¼** - ë¬¸ì„œ í•˜ë‹¨

ë‚ ì§œ í˜•ì‹:
- YYYY-MM-DD (ì˜ˆ: 2024-05-01)
- YYYY.MM.DD (ì˜ˆ: 2024.05.01)
- YYYY/MM/DD (ì˜ˆ: 2024/05/01)
- YYYYë…„ MMì›” DDì¼
â†’ ëª¨ë‘ YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ì •ê·œí™”í•˜ì„¸ìš”.

ì œì™¸ ëŒ€ìƒ:
- ë¶ˆê°€ëŠ¥í•œ ë‚ ì§œ (ì›” > 12, ì¼ > 31, ì›”/ì¼ = 0)
- í˜ì´ì§€ ë²ˆí˜¸, ë¬¸ì„œ ë²ˆí˜¸
- ì—°ë„ë§Œ ìˆëŠ” ê²½ìš° (ì˜ˆ: 2024)

í…ìŠ¤íŠ¸:
{merged_text[:6000]}{existing_info}

JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš” (dates ë°°ì—´ë§Œ):
{{"dates": ["2024-05-01", "2024-11-10", "2054-11-10"]}}"""

async def extract_with_gpt(blocks: List[Dict], existing_dates: List[str], api_key: str) -> tuple[Set[str], Dict]:
    """GPT-4o-minië¡œ ë‚ ì§œ ì¶”ì¶œ"""
    if not HAS_OPENAI or not api_key:
        return set(), {"error": "OpenAI API í‚¤ ì—†ìŒ"}

    try:
        # SSL verification bypass for WSL environment
        http_client = httpx.AsyncClient(verify=False, timeout=60.0)
        client = AsyncOpenAI(api_key=api_key, http_client=http_client)

        merged_text = merge_ocr_blocks(blocks)
        prompt = create_date_extraction_prompt(merged_text, existing_dates)

        start = datetime.now()
        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì˜ë£Œë³´í—˜ ë¬¸ì„œì—ì„œ ë‚ ì§œë¥¼ ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"},
            temperature=0.1
        )
        elapsed = (datetime.now() - start).total_seconds()

        content = response.choices[0].message.content
        parsed = json.loads(content)

        dates = set()
        for date_str in parsed.get('dates', []):
            normalized = normalize_date(date_str)
            if is_valid_date(normalized):
                dates.add(normalized)

        return dates, {
            "success": True,
            "count": len(dates),
            "elapsed": elapsed,
            "tokens": response.usage.total_tokens if response.usage else 0
        }
    except Exception as e:
        return set(), {"error": str(e)}

async def extract_with_claude(blocks: List[Dict], existing_dates: List[str], api_key: str) -> tuple[Set[str], Dict]:
    """Claude 3.5 Haikuë¡œ ë‚ ì§œ ì¶”ì¶œ"""
    if not HAS_ANTHROPIC or not api_key:
        return set(), {"error": "Anthropic API í‚¤ ì—†ìŒ"}

    try:
        # SSL verification bypass for WSL environment
        http_client = httpx.AsyncClient(verify=False, timeout=60.0)
        client = AsyncAnthropic(api_key=api_key, http_client=http_client)

        merged_text = merge_ocr_blocks(blocks)
        prompt = create_date_extraction_prompt(merged_text, existing_dates)

        start = datetime.now()
        response = await client.messages.create(
            model="claude-3-5-haiku-20241022",
            max_tokens=2048,
            temperature=0.1,
            messages=[
                {"role": "user", "content": prompt}
            ]
        )
        elapsed = (datetime.now() - start).total_seconds()

        content = response.content[0].text
        parsed = json.loads(content)

        dates = set()
        for date_str in parsed.get('dates', []):
            normalized = normalize_date(date_str)
            if is_valid_date(normalized):
                dates.add(normalized)

        return dates, {
            "success": True,
            "count": len(dates),
            "elapsed": elapsed,
            "tokens": response.usage.input_tokens + response.usage.output_tokens
        }
    except Exception as e:
        return set(), {"error": str(e)}

def normalize_date(date_str: str) -> str:
    """ë‚ ì§œ ì •ê·œí™”"""
    match = re.match(r'^(\d{4})[-./ ](\d{1,2})[-./ ](\d{1,2})$', date_str)
    if match:
        year, month, day = match.groups()
        return f"{year}-{month.zfill(2)}-{day.zfill(2)}"
    return date_str

def classify_grade(accuracy: float) -> str:
    """ë“±ê¸‰ ë¶„ë¥˜"""
    if accuracy >= 80:
        return "ìƒ"
    elif accuracy >= 60:
        return "ì¤‘"
    else:
        return "í•˜"

async def validate_case_dual_model(case: Dict, apis: Dict) -> Dict:
    """ì¼€ì´ìŠ¤ë¥¼ 2ê°œ ëª¨ë¸ë¡œ ê²€ì¦"""
    case_name = case['name']

    # Baseline ë‚ ì§œ
    baseline_file = Path(case['baseline_file'])
    if not baseline_file.exists():
        return None

    baseline_text = baseline_file.read_text(encoding='utf-8')
    baseline_dates = extract_dates_from_text(baseline_text)

    # OCR íŒŒì¼
    ocr_file = Path(case['ocr_file'])
    if not ocr_file.exists():
        return None

    # OCR ë°ì´í„° ë¡œë“œ
    if ocr_file.suffix.lower() == '.csv':
        ocr_text = ocr_file.read_text(encoding='utf-8')
        blocks = []  # CSVëŠ” ë¸”ë¡ ì •ë³´ ì—†ìŒ
        ocr_dates_regex = extract_dates_from_text(ocr_text)
    else:
        try:
            with open(ocr_file, encoding='utf-8') as f:
                ocr_data = json.load(f)
            blocks = ocr_data.get('blocks', [])
            ocr_text = '\n'.join([b.get('text', '') for b in blocks])
            ocr_dates_regex = extract_dates_from_text(ocr_text)
        except:
            return None

    # 2ê°œ ëª¨ë¸ë¡œ ë³‘ë ¬ ì²˜ë¦¬
    if blocks:
        gpt_task = extract_with_gpt(blocks, list(ocr_dates_regex), apis.get('openai', ''))
        claude_task = extract_with_claude(blocks, list(ocr_dates_regex), apis.get('claude', ''))

        results = await asyncio.gather(gpt_task, claude_task, return_exceptions=True)

        gpt_dates, gpt_meta = results[0] if not isinstance(results[0], Exception) else (set(), {"error": str(results[0])})
        claude_dates, claude_meta = results[1] if not isinstance(results[1], Exception) else (set(), {"error": str(results[1])})
    else:
        gpt_dates, claude_dates = set(), set()
        gpt_meta = claude_meta = {"error": "CSV íŒŒì¼ (ë¸”ë¡ ì—†ìŒ)"}

    # ê° ëª¨ë¸ ê²°ê³¼ ê³„ì‚°
    def calc_result(llm_dates):
        total_dates = ocr_dates_regex | llm_dates
        matched = baseline_dates & total_dates
        accuracy = (len(matched) / len(baseline_dates) * 100) if baseline_dates else 100.0
        return {
            "accuracy": accuracy,
            "grade": classify_grade(accuracy),
            "matched": len(matched),
            "total": len(total_dates),
            "llm_added": len(llm_dates)
        }

    return {
        "case_name": case_name,
        "case_type": case['type'],
        "baseline_dates": len(baseline_dates),
        "ocr_regex": len(ocr_dates_regex),
        "regex_only": calc_result(set()),
        "gpt": {**calc_result(gpt_dates), "meta": gpt_meta},
        "claude": {**calc_result(claude_dates), "meta": claude_meta}
    }

async def main():
    # API í‚¤
    apis = {
        'openai': os.environ.get('OPENAI_API_KEY', ''),
        'claude': os.environ.get('ANTHROPIC_API_KEY', '')
    }

    print("=" * 100)
    print("GPT vs Claude ëª¨ë¸ ë¹„êµ ê²€ì¦")
    print("=" * 100)
    print(f"âœ… GPT-4o-mini: {'ì‚¬ìš© ê°€ëŠ¥' if apis['openai'] else 'âŒ API í‚¤ ì—†ìŒ'}")
    print(f"âœ… Claude 3.5 Haiku: {'ì‚¬ìš© ê°€ëŠ¥' if apis['claude'] else 'âŒ API í‚¤ ì—†ìŒ'}")
    print(f"âš ï¸  Gemini 2.0 Flash: WSL SSL ì´ìŠˆë¡œ ì œì™¸")
    print()

    # ì¼€ì´ìŠ¤ ë¡œë“œ
    cases_file = Path("/home/user/VNEXSUS-25-12-30/validation_cases_28.json")
    with open(cases_file) as f:
        cases = json.load(f)

    print(f"ì´ ì¼€ì´ìŠ¤: {len(cases)}ê°œ")
    print()

    results = []
    for i, case in enumerate(cases, 1):
        print(f"[{i}/{len(cases)}] {case['name']} ê²€ì¦ ì¤‘...", flush=True)

        result = await validate_case_dual_model(case, apis)
        if result:
            results.append(result)

            # ê°„ë‹¨í•œ ê²°ê³¼ ì¶œë ¥
            print(f"  ì •ê·œì‹: {result['regex_only']['grade']} ({result['regex_only']['accuracy']:.1f}%)")
            if 'error' not in result['gpt']['meta']:
                print(f"  GPT:    {result['gpt']['grade']} ({result['gpt']['accuracy']:.1f}%) +{result['gpt']['llm_added']}ê°œ")
            if 'error' not in result['claude']['meta']:
                print(f"  Claude: {result['claude']['grade']} ({result['claude']['accuracy']:.1f}%) +{result['claude']['llm_added']}ê°œ")
        else:
            print("  âŒ ì‹¤íŒ¨")
        print()

    # ì €ì¥
    output_path = Path("/home/user/VNEXSUS-25-12-30/outputs/gpt_claude_comparison.json")
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)

    print(f"âœ… ê²°ê³¼ ì €ì¥: {output_path}")

    # í†µê³„ ì¶œë ¥
    if results:
        print()
        print("=" * 100)
        print("ëª¨ë¸ë³„ í‰ê·  ì •í™•ë„")
        print("=" * 100)

        regex_avg = sum(r['regex_only']['accuracy'] for r in results) / len(results)
        gpt_results = [r for r in results if 'error' not in r['gpt']['meta']]
        claude_results = [r for r in results if 'error' not in r['claude']['meta']]

        gpt_avg = sum(r['gpt']['accuracy'] for r in gpt_results) / len(gpt_results) if gpt_results else 0
        claude_avg = sum(r['claude']['accuracy'] for r in claude_results) / len(claude_results) if claude_results else 0

        print(f"Regex Only:     {regex_avg:.1f}%")
        print(f"GPT-4o-mini:    {gpt_avg:.1f}% ({len(gpt_results)}ê°œ ì„±ê³µ)")
        print(f"Claude 3.5 Haiku: {claude_avg:.1f}% ({len(claude_results)}ê°œ ì„±ê³µ)")

if __name__ == "__main__":
    asyncio.run(main())
